---
title: "Beyond #NeuroAI, we need #AI4Neuro---and we're going to suck at it (at first). [Part 3]"
tags: [Reflections, General Science, Science Communication, Data & Technology]
status: publish
type: post
published: False #True
header:
  overlay_image: /assets/images/blog/default_header.jpg
  overlay_filter: rgba(0,0,0,0.7)
  teaser: /assets/images/blog/default_header.jpg
classes:
  - wide
permalink: /blog/:year/:month/:day/

excerpt: ""
---



  
The core of AI in NeuroAI is that we can fit a model of computation to the data, i.e., computational tasks performed by humans and animals, whether that's classifying MNIST and ImageNet or solving a two-bit working memory task. 
Extrapolating from this principle, but replacing "model of computation" by model of X, how can we leverage AI in similar ways?
In other words, how can we use AI to fit other models, or models of other phenomena, to data?

- differentiability
- parameter inference for simulators
- "implicit models", i.e., data analysis
- blackbox control
- ???


- AI in biology, physics, climate sciences:
https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool


- known knowns and unknown unknowns: chatGPT


---

### AI for Neuroscience


[wiki_aiwinter]:https://en.wikipedia.org/wiki/AI_winter
[tweet_mineault]:https://twitter.com/patrickmineault/status/1730989784678490589
[tweet_rg]:https://twitter.com/_rdgao/status/1731376771763757298
[wiki_compneuro]:https://en.wikipedia.org/wiki/Computational_neuroscience
[trends]:https://trends.google.com/trends/explore?q=NeuroAI,AI4neuro&hl=en-GB
[mattis_ai4neuro]:https://github.com/amathislab


Fitting enough, NeurIPS---`Neural Information Processing Systems`---was arguably the modern ancestor conference for NeuroAI ("modern" because it came after "cybernetics", which was too...Soviet Union to catch on?). NeurIPS was a place for works looking at how information processing or computation happens in neural and neural-like systems, before weirdly finding itself being **the** place for completely brain-free machine learning papers for some time. Now, in 2024, as the economy goes to shit and big tech companies no longer giving 6-figure salaries to anybody that's ever written a line of `loss.backward()`, maybe we will see NeurIPS coming back to being the playground of computer neuroscientists? If the trend from this year holds up, we'll have gone full circle and come back to analyzing powerful-for-its-time artificial computing systems as we imagine how brains do things, or even as artificial brains, and this, my friends, is a tale as old as time itself. 

But if history serves us correctly, this will not be how we solve neuroscience. Or at least, this alone will not be the way. Strangely enough, I'm convinced of this after being at NeurIPS---and after visiting the Deutsches Museum and playing with some really fun fundamental physics demos--- We need an AI4Neuroscience. 

Computational neuroscience
the method becomes the model
measurements


 (no, the "neurons" in a deep neural network are not neural and we're not having this discussion here)


---
[perspective]:https://www.nature.com/articles/s41467-023-37180-x
[neurips_mineault]:https://airtable.com/appWMCgd7CqsVIRza/shrTRBBqmrT74fZLb/tbl1t9cr5qpkYsrpb


### AI for Neuroscience


[wiki_aiwinter]:https://en.wikipedia.org/wiki/AI_winter
[tweet_mineault]:https://twitter.com/patrickmineault/status/1730989784678490589
[tweet_rg]:https://twitter.com/_rdgao/status/1731376771763757298
[wiki_compneuro]:https://en.wikipedia.org/wiki/Computational_neuroscience
[trends]:https://trends.google.com/trends/explore?q=NeuroAI,AI4neuro&hl=en-GB
[mattis_ai4neuro]:https://github.com/amathislab


Fitting enough, NeurIPS---`Neural Information Processing Systems`---was arguably the modern ancestor conference for NeuroAI ("modern" because it came after "cybernetics", which was too...Soviet Union to catch on?). NeurIPS was a place for works looking at how information processing or computation happens in neural and neural-like systems, before weirdly finding itself being **the** place for completely brain-free machine learning papers for some time. Now, in 2024, as the economy goes to shit and big tech companies no longer giving 6-figure salaries to anybody that's ever written a line of `loss.backward()`, maybe we will see NeurIPS coming back to being the playground of computer neuroscientists? If the trend from this year holds up, we'll have gone full circle and come back to analyzing powerful-for-its-time artificial computing systems as we imagine how brains do things, or even as artificial brains, and this, my friends, is a tale as old as time itself. 

But if history serves us correctly, this will not be how we solve neuroscience. Or at least, this alone will not be the way. Strangely enough, I'm convinced of this after being at NeurIPS---and after visiting the Deutsches Museum and playing with some really fun fundamental physics demos--- We need an AI4Neuroscience. 

Computational neuroscience
the method becomes the model
measurements


 (no, the "neurons" in a deep neural network are not neural and we're not having this discussion here)


---
[perspective]:https://www.nature.com/articles/s41467-023-37180-x
[neurips_mineault]:https://airtable.com/appWMCgd7CqsVIRza/shrTRBBqmrT74fZLb/tbl1t9cr5qpkYsrpb



What are the defining characteristics of representations?
How stable are representations?
Are representations embodied? Are representations (a)modal? What does it mean for a representation to be modal or amodal?
What do representations look like at the neurobiological level?
Are representations distributed and extended? What does it mean for a representation to be or to not be distributed?
Do representations necessarily exist through relations (distinctions, oppositions) to other representations?
Is conscious experience exhausted by representations?
What explanatory power exactly does Cognitive Science acquire by positing representations? Are there important questions that Cognitive Science can solve without the use of representations? Are there any domains where positing representations needlessly complicate or overburden analyses of phenomena?
Could Cognitive Science exist without representations? If no - why? If yes - what would it look like?